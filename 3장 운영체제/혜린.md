# 3장 운영체제

# 3.1 운영체제와 컴퓨터

운영체제

- 사용자가 컴퓨터를 쉽게 다루게 해주는 인터페이스

❓펌웨어

- 운영체제와 유사하지만 소프트웨어를 추가로 설치할 수 없는 것

## 3.1.1 운영체제의 역할과 구조

1. **운영체제의 역할**

크게 네 가지가 있다.

- **CPU 스케줄링과 프로세스 관리**
    
    CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리
    
- **메모리 관리**
    
    한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 하는 지 관리
    
- **디스크 파일 관리**
    
    디스크 파일을 어떠한 방법으로 보관할 지 관리
    
- **I/O 디바이스 관리**
    
    I/O 디바이스들인 마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리
    

❓I/O

- I/O는 입력(Input)/출력(Output)의 약자로, 컴퓨터 및 주변장치에 대하여 데이터를 전송하는 프로그램, 운영 혹은 장치를 일컫는 말이다.
- I/O 요청
    - 입출력 함수, 데이터베이스, 네트워크, 파일 접근 등에 관한 일

1. **운영체제의 구조**

![images_dddooo9_post_ae507c30-a412-4af4-844e-7242fffcd2c6_image.png](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%2039a0ee2ebe91473dbe49f8ec4bed428b/images_dddooo9_post_ae507c30-a412-4af4-844e-7242fffcd2c6_image.png)

크게 6가지로 나뉜다.

- 유저 프로그램
- GUI
    - 사용자는 커널에 직접 접근할 수 없기 때문에 운영체제가 제공하는 인터페이스를 사용해 커널에 명령을 내려야 한다.
    - 사용자와 애플리케이션은 인터페이스를 통해 커널에 명령을 전달하고, 인터페이스를 통해 실행결과를 전달받는다.
    - 운영체제가 제공하는 대표적인 인터페이스는 GUI, CLI가 있다.
- 커널
    - 프로세스, 메모리, 저장장치를 관리하는 핵심적인 기능을 한다.
    - 시스템 호출(System Call)과 드라이버가 존재한다.
- 시스템콜
    - 애플리케이션이 직접 하드웨어 자원에 접근하거나 수정하려 할 때 실수(중요 데이터를 덮어쓴다던지 등)를 할 수 있다.
    - 이러한 사태를 막기 위해 커널은 시스템 콜이라는 시스템 자원 사용과 관련된 함수를 제공한다. (write(), read(), printf() 같은 것들)
    - 즉 애플리케이션이 하드웨어에 접근해야하거나 운영체제가 제공하는 서비스를 이용하기 위해서는 커널 함수를 호출하는 시스템 콜을 사용해야 한다.
    - 또한 시스템 콜을 제공함으로써 운영체제는 컴퓨터 자원을 보호하게 된다.
    - 시스템 콜은 이후에 나올 인터럽트 중 하나인 소프트웨어 인터럽트(Trap)의 한 종류이다.
    - modebit
        - 1 또는 0의 값을 가지는 플래그 변수이다.
        - 시스템콜은 작동시 modebit을 참고해서 유저 모드와 커널 모드를 구분한다.
        - 카메라, 키보드 등 I/O 디바이스는 운영체제를 통해서만 작동해야 한다. 유저 모드일 경우에는 시스템콜을 못하게 막아서 한정된 일만 가능하게 한다.
- 드라이버
    - 커널과 하드웨어의 인터페이스를 드라이버라고 한다.
    - 보통 커널은 입출력의 기본적인 부분만 제작하기 때문에 마우스, 키보드 같은 하드웨어는 꽂기만 해도 보통 작동하게 된다.
    - 하지만 복잡한 하드웨어의 경우 하드웨어 제작사가 만든 소프트웨어를 따로 설치하여 사용해야하며 이때 이 소프트웨어를디바이스 드라이버라고 합니다.
- 하드웨어

여기서 **GUI, 시스템콜, 커널, 드라이버** 부분을 **운영체제**라 지칭한다.

❓ CUI

- 그래픽이 아닌 명령어로 처리하는 인터페이스

❓ 유저 모드

- 유저가 접근할 수 있는 영역을 제한적으로 두며 컴퓨터 자원에 함부러 침범하지 못하게 하는 모드

❓ 커널 모드

- 모든 컴퓨터 자원에 접근할 수 있는 모드

❓ 커널

- 운영체제의 핵심 부분이자 시스템콜 인터페이스를 제공하여 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적 역할을 한다.

## 3.1.2 컴퓨터의 요소

CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져있다.

- **CPU**

커널이 프로그램을 메모리에 올려 프로세스로 만들면 CPU가 이를 처리한다.

- 산술논리연산장치
    - 덧셈, 뺄셈 같은 두 숫자의 산술 연산과 베타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로
- 제어장치
    - 프로세스 조작을 지시하는 CPU의 한 부품
    - 입출력장치 간 통신을 제어하고 명령어들을 읽고 해석하며 데이터 처리를 위한 순서를 결정한다.
- 레지스터
    - CPU 안에 있는 매우 빠른 임시기억장치
    - CPU와 직접 연결되어 있어 연산 속도가 메모리보다 수십 배에서 수백 배까지 빠르다.
    - CPU는 자체적으로 데이터를 저장할 방법이 없어 레지스터를 거쳐 데이터를 전달한다.

❓ CPU의 연산 처리는 어떻게 이루어지는가?

1. 제어장치가 메모리에 계산할 값을 로드한다. 또한 레지스터에도 로드한다.
2. 제어장치가 레지스터에 있는 값을 계산하라고 산술논리연산장치에 명령한다.
3. 제어장치가 계산된 값을 다시 ‘레지스터에서 메모리로’ 계산한 값을 저장한다.

- 인터럽트
    - 보통 프로세스가 작업 중 운영체제에게 CPU 제어권을 넘기기 위해 사용한다.
    - 우선 순위가 존재하며 하드웨어 인터럽트, 소프트웨어 인터럽트 두 가지로 나뉜다.
    - 하드웨어 인터럽트
        - 키보드나 마우스를 연결하는 일 등의 IO 디바이스에서 발생하는 인터럽트를 말한다.
        - 인터럽트 라인이 설계된 이후, 순차적인 인터럽트 실행을 중지하고 운영체제에 시스템콜을 요청해서 원하는 디바이스로 향해 디바이스에 있는 작은 로컬 버퍼에 접근하여 일을 수행한다.
    - 소프트웨어 인터럽트
        - 트랩(trap)이라고도 한다. 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동한다.
        - 프로그램이 스스로 자신의 CPU 자원을 운영체제에게 넘기는 것이라 엄밀히는 인터럽트가 아니다.
        - Exception(프로그램이 오류를 범한 경우)과 System call(프로그램이 커널 함수를 호출한 경우)이 있다.
        
- **DMA 컨트롤러**
    - I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치를 뜻한다.
    - CPU 에만 너무 많은 인터럽트 요청이 들어오기 때문에 CPU 부하를 막아주고, 보조해준다.
    - 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 하는 것을 방지한다.

- **메모리**
    - 전자회로에서 데이터나 상태, 명렁어 등을 기록하는 장치를 말한다.
    - 보통 RAM을 일컬어 메모리라고 한다.
    - CPU는 계산, 메모리는 기억을 담당한다.
    
- **타이머**
    - 특정 프로그램에 시간 제한을 다는 역할을 한다.

- **디바이스 컨트롤러**
    - 컴퓨터와 연결되어 있는 IO 디바이스들의 작은 CPU를 말한다.

# 3.2 메모리

CPU는 그저 메모리에 올라와 있는 프로그램의 명령어들을 실행한다. 

## 3.2.1 메모리 계층

- 레지스터
    - CPU 안에 있는 작은 메모리이다.
    - 휘발성, 속도 가장빠름, 기억 용량이 가장 작다.
- 캐시
    - L1, L2 캐시를 지칭한다.
    - 휘발성, 속도 가장빠름, 기억 용량이 작다. L3 캐시도 있다.
- 주기억장치
    - RAM을 가리킨다. 휘발성, 속도 보통, 기억 용량이 보통이다.
- 보조기억장치
    - HDD, SDD을 일컬으며 휘발성, 속도 낮음, 기억 용량이 많다.

**캐시 히드와 캐시 미스**

- **캐시 미스(Cache Miss)**
    - 요청한 데이터나 연산의 결과가 캐시에 없는 경우 시스템은 본래 소스(예: 메인 메모리, 데이터베이스)에서 데이터를 가져와 캐시에 저장하고, 동시에 클라이언트에게 결과를 반환한다.
- **캐시 히트(Cache Hit)**
    - 요청한 데이터나 연산의 결과가 캐시에 있는 경우 시스템은 캐시에서 **빠르게** 데이터를 읽어와 클라이언트에게 결과를 반환한다.
- 캐시 매핑
    - 캐시가 히트되기 전에 매핑하는 방법을 말한다.
    - CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때를 기반으로 설명한다.
    - 직접 매핑
    - 연관 매핑
    - 집합 연관 매핑
- 웹 브라우저의 캐시
    - 쿠키
        - 만료 기간이 있는 키-값 저장소
    - 로컬 스토리지
        - 만료 기간이 없는 키-값 저장소
    - 세션 스토리지
        - 만료 기간이 없는 키-값 저장소
- 데이터 베이스의 캐싱 계층
    - 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 ‘캐싱 계층’으로 둬서 성능을 향상시키기도 한다.

## 3.2.2 메모리 관리

운영체제 대표적인 할 일 중 하나이다.

1. 가상 메모리
    - 메모리 관리 기법의 하나이다.
    - 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것을 말한다.
    - 가상 주소
        - 가상적으로 주어진 주소
        - 메모리 관리장치(MMU(에 의해 실제 주소로 변환된다.
        - 따라서 사용자는 실제 주소를 의식할 필요 없이 프로그램을 구축할 수 있게 된다.
    - 실제 주소
        - 실제 메모리상의 주소
        - 가상 메모리는 가상 주소와 실제 주소가 매핑 돼 있고 프로세스의 주소 정보가 들어 있는 ‘페이지 테이블’ 로 관리된다. 이 때 속도 향상을 위해 TLB를 쓴다.
        - 가상 주소에서 바로 페이지 테이블로 가는 것이 아니라 TLB에서 있는지를 확인하고 만약 없다면 페이지 테이블로 가서 실제 주소를 가져온다.
        

❓ TLB

메모리와 CPU 사이에 있는 주소 변환을 위한 캐시이다.

페이지 테이블에 있는 리스트를 보관하며 CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층이다.

앞서 설명한 것처럼 가상 메모리는 작은 메모리를 매우 큰 메모리로 보이게끔 하는 것. 따라서 참조하려는 메모리 영역이 실제에는 없을 수 있다.

- 페이지 폴트
    - 가상메모리만 존재하고 실제 메모리인 RAM이 없거나, 없는 데이터에 접근하면 발생하는 것이다.
- 스와핑
    - 메모리의 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 ‘마치 메모리처럼’ 불러와 쓰는 것을 말한다.
- 페이지 폴트와 스와핑의 과정
    1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제에 알린다.
    2. 운영체제는 CPU의 동작을 잠시 멈춘다
    3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾는다. 물리 메모리에도 없다면 스와핑이 발동된다.
    4. 비어있는 프레임에 해당 페이지를 로드하고 페이지 테이블을 최신화한다.
    5. 중단되었던 CPU를 다시 시작한다.
    

❓ 페이지

가상 메모리를 사용하는 최소 크기 단위

❓ 프레임

실제 메모리를 사용하는 최소 크기 단위

1. **스레싱**
- 메모리의 페이지 폴트율이 높은 것을 의미하며 컴퓨터의 심각한 성능 저하 초래한다.
- 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생하며, 폴트가 일어나면 CPU이용률은 낮아진다.
- CPU 이용률이 낮아지게 되면 운영체제는 CPU가 일을 안한다고 생각하고 CPU에 프로세스를 메모리에 올리게 되며 악순환이 반복되어 "스레싱"이 일어난다.
- 해결방법
    1. 하드웨어적으로 해결
        - 메모리 늘리기: 물리 메모리 용량을 증가시켜 스와핑과 페이지 폴트의 빈도를 줄인다.
        - HDD를 사용한다면 SSD로 바꾸기
    2. 운영체제에서 해결
        - 작업세트
            - 프로세스의 과거 사용이력을 기반으로 많이 사용하는 페이지 집합을 만들어 한꺼번에 미리 메모리를 로드하는 것이다.
            - 프로세스의 작업세트(활발하게 사용되는 페이지 집합)를 추적하여 메모리 할당을 최적화한다.
        - PFF(page fault frequency)
            - 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만들고 상한선에 도달한다면 프레임을 늘리고, 하한선에 도달한다면 프레임을 줄이는 방법이다.

1. **메모리 할당**
- 연속 할당
    - 메모리에 연속적으로 공간을 할당하는 것을 말한다.
    - 고정 분할 방식
        - 메모리를 미리 나누어 관리하는 방식
        - 내부 단편화 발생
            - 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
    - 가변 분할 방식
        - 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용함
        - 외부 단편화 발생 가능성 있음
            - 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상
        - 최초적합, 최적적합, 최악적합이 존재
- 불연속 할당
    - 현대 운영체제가 사용하는 방법으로 페이징 기법이 있다. 이외에도 세그멘테이션, 페이지드 세그멘테이션이 있다.
    - 페이징
        - 동일한 크기의 페이지 단위로 나뉘어 메모리의 서로 다른 위치에 프로세스를 할당한다.
        - 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해진다.
    - 세그멘테이션
        - 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식
        - 프로세스가 코드, 데이터, 스택, 힙 등으로 이루어지는데, 코드와 데이터 등 이를 기반으로 나눌 수도 있으며 함수 단위로 나눌 수도 있음
        - 공유와 보안 측면에서 좋으며 홀 크기가 균일하지 않은 문제가 발생한다.
    - 페이지드 세그멘테이션
        - 공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것

1. **페이지 교체 알고리즘**

페이지 교체 알고리즘을 기반으로 스와핑이 일어나며, 스와핑은 많이 일어나지 않도록 설계되어야 한다. 

- 오프라인 알고리즘(offline algorithm)
    - 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘이며, 가장 좋은 방법
    - 미래에 사용되는 프로세스를 우리가 알 수가 없으니 사용할 수 없는 알고리즘
- FIFO (First In First Out)
    - 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
- LRU (Least Recentle Used)
    - 참조가 가장 오래된 페이지를 바꿈
    - 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 하는 문제가 있음
    - LRU 구현을 프로그래밍으로 구현할 때는 2개의 자료구조로 구현한다.
        - 해시 테이블
            - 이중 연결 리스트에서 빠르게 찾을 수 있도록 쓰고,
        - 이중 연결 리스트
            - 한정된 메모리를 나타냄
    - NUR (Not Used Recently)
        - LRU 에서 발전한 알고리즘. clock 알고리즘
        - 0과 1을 가진 비트를 둠. 1은 최근에 참조되었고 0은 참조되지 않음을 의미.
        - 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고, 해당 부분을 1로 바꾸는 알고리즘
- LFU
    - 가장 참조 횟수가 적은 페이지를 교체한다.
    

## 3.3 프로세스와 스레드

- 프로세스
    - 컴퓨터에서 실행되고 있는 프로그램
    - CPU 스케줄링의 대상이 되는 작업이라는 용어와 거의 같은 의미로 쓰임
- 스레드
    - 프로세스 내 작업의 흐름

프로그램이 메모리에 올라가면 프로스세가 되는 인스턴스화가 일어난다.

이후 운영체제 CPU 스케줄러에 따라 CPU가 프로세스를 실행한다.

## 3.3.1 프로세스와 컴파일 과정

- 프로세스
    - 프로그램으로부터 인스턴스화 된 것
    - 프로그램
        - 컴파일러가 컴파일 과정을 거쳐 기계어로 번역되어 실행될 수 있는 파일이 되는 것
- 프로세스의 컴파일 과정
    - 전처리
        
        코드에서 주석을 제거하고 #include 같은 헤더 파일을 병합해 매크로를 치환한다.
        
    - 컴파일러
        
        오류 처리, 코드 최적화를 하고 어셈블리어로 변환한다.
        
    - 어셈블러
        
        어셈블리어는 목적 코드(object code)로 변환된다.
        
    - 링커
        
        프로그램 내에 있는 라이브러리/파일들과 목적 코드를 결합해서 실행 파일을 만든다. 실행 파일은 .exe/.out 확장자를 가진다.
        
- 정적 라이브러리와 동적 라이브러리
    - 정적 라이브러리
        - 프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식
        - 시스템 환경 등 외부 의존도가 낮은 장점 존재
        - 코드 중복 등 메모리 효율성이 떨어지는 단점 존재
    - 동적 라이브러리
        - 프로그램 실행 시 필요할 때만 DLL이라는 함수 정보를 통해 참조하는 방식
        - 메모리 효율성에서 장점
        - 외부 의존도가 높다는 단점 존재

## 3.2.2 프로세스의 상태

1. 생성상태
    
    프로세스가 생성 된 상태
    
    - fork()
        - 부모 프로세스의 주소 공간을 그대로 복사 (공간만 복사할 뿐 부모 프로세스의 비동기 작업 등을 상속하지는 않는다)
        - 새로운 자식 프로세스를 생성하는 함수
    - exec()
        - 새롭게 프로세스를 생성하는 함수
        
2. 대기 상태
    
    메모리 공간이 충분하면 메모리를 할당받고 아니면 그대로 대기한다.
    
    또한 CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태이다.
    
3. 대기 중단 상태
    
    메모리 부족으로 일시 중단된 상태
    
4. 실행 상태
    
    CPU 소유권과 메모리를 할당받고 인스트럭션을 수행 중인 상태를 의미한다. CPU burst가 일어났다고도 표현한다.
    
5. 중단 상태
    
    이벤트가 발생하고 기다리며 프로세스가 차단된 상태이다. I/O 디바이스로 인터럽트가 일어나면 발생하기도 한다. 
    ex) 프린트를 하는데 잠시 프로세스가 멈춘 것 같은 상태
    
6. 일시 중단 상태
일시 중단 상태는 대기 중단과 유사하다. 중단되고 다시 실행되려고 했지만 메모리가 부족해서 일시 중단된 상태이다.

1. 종료 상태
종료 상태는 메모리, CPU 소유권을 모두 놓고 가는 상태이다. 종료에는 자연스러운 종료, 부모 프로세스가 자식 프로세스를 강제 종료시키는 비자발적 종료(abort)가 있다.

## 3.3.3 프로세스의 메모리 구조

![images_cchloe2311_post_9a74f36f-fc70-4292-8302-9884f9826987_image.png](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8B%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%A7%E1%86%BC%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%A6%2039a0ee2ebe91473dbe49f8ec4bed428b/images_cchloe2311_post_9a74f36f-fc70-4292-8302-9884f9826987_image.png)

1. 스택
    - 동적 데이터 영역
    - 지연변수, 매개변수, 리턴값 등 **잠시 사용되었다가 사라지는 데이터**를 저장하는 영역이다.
    - 함수 호출 시 할당되고 함수 반환 시 소멸된다.
    - 로드 시(컴파일 타임) 크기가 결정됩니다.
2. 힙
    - 동적 데이터 영역
    - 메모리 주소 값에 의해서만 참조되고 사용되기 때문에 프로그램 동작 시 (런타임)에 크기가 결정된다.
3. 데이터 영역
    - 전역 변수와 정적 변수가 저장된다.
    - 이 변수들은 프로그램이 시작될 때 할당되어 프로그램 종료 시 소멸된다.
    - 더 자세히 들어가면 BSS (Block Stated Symbol) 영역과 Data 영역으로 나뉜다.
    - BSS 영역에는 초기화되지 않은 전역변수가 저장된다.
    - 초기화 된 전역 변수는 Data 영역에 저장되어 비휘발성 메모리인 ROM에 저장된다.
4. 코드 영역
    - 정적 데이터 영역
    - 실행할 프로그램의 코드가 저장된다.
    - CPU는 이 영역에서 명령어를 하나씩 가져와서 처리한다.

## 3.3.4 PCB

1. PCB(Process Control Block)
- 운영체제에서 프로세스에 대한 메타데이터를 저장한 ‘데이터’를 말한다.
- 운영체제는 프로세스가 생성되면 해당 PCB를 생성한다.
- 일반 사용자가 접근하지 못하도록 커널 스택의 가장 앞부분에서 관리한다.

❓ 메타데이터

데이터에 관한 구조화된 데이터이자 데이터를 설명하는 작은 데이터.

대량의 정보 가운데에서 찾고 있는 정보를 효율적으로 찾아내서 이용하기 위해 일정한 규칙에 따라 콘텐츠에 대해 부여되는 데이터

1. PCB 구조
- 프로세스 스케줄링 상태: '준비', '일시중단' 등 프로세스가 CPU에 대한 소유권을 얻은 이후의 상태
- 프로세스 ID: 프로세스 ID, 해당 프로세스의 자식 프로세스 ID
- 프로세스 권한: 컴퓨터 자원 또는 I/O 디바이스에 대한 권한 정보
- 프로그램 카운터: 프로세스에서 실행해야 할 다음 명령어의 주소에 대한 포인터
- CPU 레지스터: 프로세스를 실행하기 위해 저장해야 할 레지스터에 대한 정보
- CPU 스케줄링 정보: CPU 스케줄러에 의해 중단된 시간 등에 대한 정보
- 계정 정보: 프로세스 실행에 사용된 CPU 사용량, 실행한 유저의 정보
- I/O 상태 정보: 프로세스에 할당된 I/O 디바이스 목록

1. 컨텍스트 스위칭
- PCB를 교환하는 과정
- 한 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해서 발생한다.
- 어떠한 시점에서 실행되고 있는 프로세스는 단 한개이며, 다른 프로세스와의 컨텍스트 스위칭이 아주 빠른 속도로 실행되고 있기 때문에 여러 개의 프로세스가 동시에 구동되는 것 처럼 느껴진다.
- 현대 컴퓨터는 멀티 코어 CPU를 가진다. 하지만 컨텍스트 스위칭을 설명할 때는 싱글코어를 기준으로 설명한다.
- 프로세스 A가 실행하다 멈추고, 프로세스 A의 PCB를 저장하고 다시 프로세스 B를 로드하여 실행. 그리고 다시 프로세스 B의 PCB를 저장하고 프로세스 A의 PCB를 로드
- 그래서 컨텍스트 스위칭이 일어날 때 유휴 시간이 발생한다.
- 추가적으로 캐시미스라는 비용이 더 든다.

❓ 캐시 미스

컨텍스트 스위칭이 일어날 때 프로세스가 가지고 있는 메모리 주소가 그대로 있으면 잘못된 주소 변환이 생기므로 캐시 클리어 과정을 겪게 되고 이 때문에 캐시미스가 발생

❓ 스레드에서의 컨텍스트 스위칭

컨텍스트 스위칭은 스레드에서도 일어난다.

스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에 스레드 컨텍스트 스위칭의 경우 비용이 더 적고 시간도 더 적게 걸린다.

## 3.3.5 멀티 프로세싱

- 여러 개의 '프로세스', 즉 멀티프로세스를 통해 동시에 두 가지 이상의 일을 수행할 수 있는 것
- 하나 이상의 일을 병렬로 처리. 신뢰성이 높다.

1. 웹 브라우저
    - 멀티프로세스 구조
        - 브라우저 프로세스: 주소 표시줄, 북마크 막대, 뒤로 가기 버튼, 앞으로 가기 버튼 등을 담당하며 네트워크 요청이나 파일 접근 같은 권한을 담당
        - 렌더러 프로세스: 웹 사이트가 '보이는' 부분의 모든 것을 제어
        - 플러그인 프로세스: 웹 사이트에서 사용하는 플러그인을 제어
        - GPU 프로세스: GPU를 이용해서 화면을 그리는 부분을 제어
        - 
2. IPC(Inter Process Communication)
    - 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘
    - 클라이언트, 서버 통신도 IPC의 예시
    - 종류로는 공유 메모리, 파일, 소켓, 익명 파이프, 명명 파이프, 메시지 큐
    - 메모리가 완전히 공유되는 스레드보다는 속도가 떨어짐
        - 공유 메모리
            - 여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 공유 버퍼를 생성
            - 불필요한 데이터 복사의 오버헤드가 발생하지 않아 가장 빠르며 같은 메모리 영역을 여러 프로세스가 공유하기 때문에 동기화가 필요
            - 하드웨어 관점에서 공유 메모리는 CPU가 접근할 수 있는 큰 랜덤 접근 메모리인 RAM을 가리킬 수 있음
        - 파일
            - 디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터
        - 소켓
            - 동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터를 의미
            - TCP, UDP
        - 익명 파이프(unamed pipe)
            - 프로세스 간에 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고받으며, 단방향 방식의 읽기 전용, 쓰기 전용 파이프를 만들어서 작동하는 방식
            - 부모, 자식 프로세스 간에만 사용가능하고 다른 네트워크 상에서는 사용이 불가능
        - 명명된 파이프(named pipe)
            - 파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 이중 파이프를 말함.
            - 클라이언트/서버 통신을 위한 별도의 파이프를 제공하며, 여러 파이프를 동시에 사용할 수 있다.
        - 메시지 큐
            - 메시지를 큐 데이터 구조 형태로 관리하는 것을 의미
            - 커널의 전역변수 형태 등 커널에서 전역적으로 관리되며 다른 IPC 방식에 비해서 사용 방법이 매우 직관적이고 간단하며 다른 코드의 수정 없이 단지 몇 줄의 코드를 추가시켜 간단하게 메시지 큐에 접근할 수 있다는 장점 존재
            - 공유 메모리를 통해 IPC를 구현할 때 쓰기 및 읽기 빈도가 높으면 동기화 때문에 기능을 구현하는 것이 매우 복잡해지는데, 이때의 대안으로 사용 가능

## 3.3.6 스레드와 멀티스레딩

1. 스레드
    - 프로세스의 실행 가능한 가장 작은 단위
    - 여러 스레드를 가질 수 있다.
    - 코드, 데이터, 힙은 스레드끼리 서로 공유한다.
    - 그 외의 영역은 각각 생성된다.
2. 멀티스레딩
    - 프로세스 내 작업을 여러 개의 스레드, 멀티스레드로 처리하는 기법이며 스레드끼리 서로 자원을 공유하기 때문에 효율성이 높음
    - 동시성에도 큰 장점

❓ 동시성

서로 독립적인 작업들을 작은 단위로 나누고 동시에 실행되는 것 처럼 보여주는 것

## 3.3.7 공유 자원과 임계 영역

1. 공유 자원
- 시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수 등을 의미
- 이 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황을 경쟁 상태라고 함
- 동시에 접근을 시도할 때 접근의 타이밍이나 순서 등이 결괏값에 영향을 줄 수 있는 상태

1. 임계 영역
- 둘 이상의 프로세스, 스레드가 공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드 영역
- 임계 영역을 해결하기 위한 방법은 크게 뮤텍스, 세마포어, 모니터가 있음. 이 방법 모두 상호 배제, 한정 대기, 융통성이란 조건을 만족
- 토대가 되는 메커니즘은 잠금(lock)

❓ 상호배제: 한 프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없음

❓ 한정 대기: 특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안됨

❓ 융통성: 한 프로세스가 다른 프로세스의 일을 방해해서는 안됨

- 뮤텍스
    - 프로세스나 스레드가 공유 자원을 lock()을 통해 잠금 설정하고 사용한 후에는 unlock()을 통해 잠금 해체하는 객체.
    - 잠금이 설정되면 다른 프로세스나 스레드는 잠긴 코드 영역에 점근할 수 없고 해제는 그와 반대
    - 잠금 또는 잠금 해제라는 상태만을 가짐
- 세마포어
    - 일반화된 뮤텍스.
    - 간단한 정수 값과 두 가지 함수 wait(P 함수), signal(V 함수)로 공유 자원에 대한 접근을 처리
    - wait()는 자신의 차례가 올 때까지 기다리는 함수, signal()은 다음 프로세스로 순서를 넘겨주는 함수
    - 프로세스나 스레드가 공유 자원에 접근하면 세마포어에서 wait() 작업을 수행하고 프로세스나 스레드가 공유 자원을 해제하면 세마포어에서 signal() 작업을 수행
    - 조건 변수가 없고 프로세스나 스레드가 세마포어 값을 수정할 때 다른 프로세스나 스레드는 동시에 세마포어 값을 수정할 수 없음
        - 바이너리 세마포어
            - 0과 1의 두 가지 값만 가질 수 있는 세마포어
            - 뮤텍스랑 비슷하다고 생각할 수 있지만 뮤텍스는 잠금을 기반으로 상호배제가 일어나는 '잠금 메커니즘'이고, 세마포어는 신호를 기반으로 상호 배제가 일어나는 '신호 메커니즘'임
        - 카운팅 세마포어
            - 여러 개의 값을 가질 수 있는 세마포어, 여러 자원에 대한 접근을 제어하는데 사용
        - 모니터
            - 둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 인터페이스만 제공
            - 모니터큐를 통해 공유 자원에 대한 작업들을 순차적으로 처리할 수 있음
            - 세마포어보다 구현하기 쉽고, 상호 배제는 자동인 반면에, 세마포어에서는 상호 배제를 명시적으로 구현해야 하는 차이가 있음

## 3.3.8 교착 상태

두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태를 말한다.

1. 교착 상태 원인
- 상호 배제: 한 프로세스가 자원을 독점, 다른 프로세스들은 접근이 불가능
- 점유 대기: 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태
- 비선점: 다른 프로세스의 자원을 강제적으로 가져올 수가 없는 상태
- 환형 대기: 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 요구하는 등 서로가 서로의 자원을 요구하는 상황을 말함

1. 교착상태 해결 방법
- 자원을 할당할 때 애초에 조건이 성립되지 않도록 설계
- 교착 상태 가능성이 없을 때만 자원이 할당되며, 프로세스당 요청할 자원들의 최대치를 통해 자원 할당 가능 여부를 파악하는 '은행원 알고리즘'을 씀
- 교착 상태가 발생하면 사이클이 있는지 찾아보고 이에 관련된 프로세스를 한 개씩 지움
- 교착 상태는 매우 드물게 일어나기 때문에 이를 처리하는 비용이 더 커서 교착 상태가 발생하면 사용자가 작업을 종료함. '응답 없음'이 뜨는 경우

❓은행원 알고리즘

총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 또는 불안정 상태로 나누고 안정 상태로 가도록 자원을 할당하는 알고리즘

# 3.4 CPU 스케줄링 알고리즘

CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당

CPU 이용률은 높게, 주어진 시간에 많은 일을 하게, 준비 큐에 있는 프로세스는 적게, 응답 시간은 짧게 설정하는 것을 목표로 함

## 3.4.1 비선점형 방식

- 프로세스가 스스로 CPU 소유권을 포기하는 방식
- 강제로 프로세스를 중지하지 않음컨텍스트 스위칭으로 인한 부하가 적음

1. FCFS(Frist Come, First Served.)
    - 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
    - 준비 큐에서 오래 기다리는 현상(convoy effect)이 발생하는 단점
2. SJF(Shortest Job First.)
    - 실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘
    - 긴 시간을 가진 프로세스가 실행되지 않는 현상이 일어나며 평균 대기 시간이 가장 짧음
    - 실제로는 실행 시간을 알 수 없기 때문에 과거의 실행했던 시간을 토대로 추측함
3. 우선순위
    - 기존 SJF 스케줄링의 경우 긴 시간을 가진 프로세스가 실행되지 않는 현상 존재
    - 따라서 오랜된 작업일수록 '우선순위를 높이는 방법'을 통해 단점을 보완한 알고리즘

## 3.4.2 선점형 방식

- 현대 운영체제가 쓰는 방식
- 알고리즘에 의해 프로세스를 중단시켜 버리고 강제로 다른 프로세스에 CPU 소유권을 할당하는 방법
1. 라운드 로빈
    - 현대 컴퓨터가 쓰는 스케줄링인 우선순위 스케줄링의 일종
    - 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 가는 알고리즘
    - q만큼의 할당 시간이 부여되었고 N개의 프로세스가 운영된다고 하면 (N-1)*q 시간이 지나면 자신의 차례가 옴
    - 할당 시간이 너무 크면 FCFS가 되고 짧으면 컨텍스트 스위칭이 잦아져서 오버헤드, 즉 비용이 커짐
    - 전체 작업 시간은 길어지지만 평균 응답 시간은 짧아진다는 특징이 있음
    - 로드밸런서에서 트래픽 분산 알고리즘으로 쓰임
2. SRF
    - 중간에 실행 시간이 더 짧은 작업이 들어와도 기존 짧은 작업을 모두 수행하고 그 다음 짧은 작업을 이어나가는데, SRF는 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 해당 프로세스를 수행하는 알고리즘
3. 다단계 큐
    - 우선순위에 따른 준비 큐를 여러 개 사용하고, 큐마다 라운드 로빈이나 FCFS 등 다른 스케줄링 알고리즘을 적용한 것을 말함
    - 큐 간의 프로세스 이동이 안되므로 스케줄링 부담이 적지만 유연성이 떨어짐
